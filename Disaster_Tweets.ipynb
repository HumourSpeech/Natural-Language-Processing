{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"datasets/train.csv\")\n",
    "test_df = pd.read_csv(\"datasets/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Lower All the Cases\n",
    "train_df['text'] =train_df['text'].str.lower()\n",
    "\n",
    "## Removing Special Characters\n",
    "train_df['text'] = train_df['text'].apply(lambda x:re.sub('[^a-z A-Z 0-9-]+','',x))\n",
    "\n",
    "## Removing the stopwords\n",
    "# train_df['text'] = train_df['text'].apply(lambda x:\" \".join([y for y in x.split() if y not in stopwords.words('english')]))\n",
    "stop_words = set(stopwords.words('english'))\n",
    "train_df['text'] = train_df['text'].apply(lambda x: \" \".join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "## Removing url\n",
    "train_df['text'] = train_df['text'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?','', str(x)))\n",
    "\n",
    "## Removing  html tags\n",
    "train_df['text'] = train_df['text'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
    "\n",
    "## Removing any additional spaces\n",
    "train_df['text'] = train_df['text'].apply(lambda x: \" \".join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN       deeds reason earthquake may allah forgive us   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  residents asked shelter place notified officer...   \n",
       "3   6     NaN      NaN  13000 people receive wildfires evacuation orde...   \n",
       "4   7     NaN      NaN  got sent photo ruby alaska smoke wildfires pou...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatizer \n",
    "from  nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "train_df['text'] = train_df['text'].apply(lambda x:lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resident asked shelter place notified officer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13000 people receive wildfire evacuation order...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN         deed reason earthquake may allah forgive u   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  resident asked shelter place notified officer ...   \n",
       "3   6     NaN      NaN  13000 people receive wildfire evacuation order...   \n",
       "4   7     NaN      NaN  got sent photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Lower All the Cases\n",
    "test_df['text'] =test_df['text'].str.lower()\n",
    "\n",
    "## Removing Special Characters\n",
    "test_df['text'] = test_df['text'].apply(lambda x:re.sub('[^a-z A-Z 0-9-]+','',x))\n",
    "\n",
    "## Removing the stopwords\n",
    "# test_df['text'] = test_df['text'].apply(lambda x:\" \".join([y for y in x.split() if y not in stopwords.words('english')]))\n",
    "stop_words = set(stopwords.words('english'))\n",
    "test_df['text'] = test_df['text'].apply(lambda x: \" \".join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "## Removing url\n",
    "test_df['text'] = test_df['text'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?','', str(x)))\n",
    "\n",
    "## Removing  html tags\n",
    "test_df['text'] = test_df['text'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\n",
    "\n",
    "## Removing any additional spaces\n",
    "test_df['text'] = test_df['text'].apply(lambda x: \" \".join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "test_df['text'] = test_df['text'].apply(lambda x:lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>typhoon soudelor kill 28 china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                        happened terrible car crash\n",
       "1   2     NaN      NaN  heard earthquake different city stay safe ever...\n",
       "2   3     NaN      NaN  forest fire spot pond goose fleeing across str...\n",
       "3   9     NaN      NaN               apocalypse lighting spokane wildfire\n",
       "4  11     NaN      NaN              typhoon soudelor kill 28 china taiwan"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"text\"]\n",
    "y_train = train_df[\"target\"]\n",
    "X_test = test_df[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Word to vec on train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the reviews\n",
    "X_train_tokens = [word_tokenize(review.lower()) for review in X_train]\n",
    "X_test_tokens = [word_tokenize(review.lower()) for review in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec on training tokens\n",
    "word2vec_model = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, min_count=2, workers=4, sg=1)\n",
    "word2vec_model = Word2Vec(sentences=X_test_tokens, vector_size=100, window=5, min_count=2, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(tokens, model, vector_size):\n",
    "    \"\"\"Compute the average Word2Vec for a list of tokens.\"\"\"\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv.index_to_key]\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reviews to average Word2Vec vectors\n",
    "X_train_avg = np.array([avg_word2vec(tokens, word2vec_model, 100) for tokens in X_train_tokens])\n",
    "X_test_avg = np.array([avg_word2vec(tokens, word2vec_model, 100) for tokens in X_test_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.02867678e-01,  1.60298988e-01,  1.63621791e-02,  1.16022630e-02,\n",
       "       -2.38105953e-02, -2.61495262e-01,  7.22299051e-03,  2.21647695e-01,\n",
       "       -9.18482691e-02, -1.05311774e-01, -1.13378070e-01, -2.15209752e-01,\n",
       "        2.57335277e-03,  7.30944574e-02,  3.22373696e-02, -1.87296599e-01,\n",
       "        9.85176861e-03, -2.20953703e-01,  6.77561909e-02, -2.66245186e-01,\n",
       "        1.02455400e-01,  2.09868215e-02,  1.42470345e-01,  2.78335549e-02,\n",
       "       -7.21919388e-02, -1.00523829e-02, -1.75295740e-01, -8.45400915e-02,\n",
       "       -9.78691727e-02, -2.87717078e-02,  1.36251315e-01,  5.60353983e-05,\n",
       "       -4.77746576e-02, -1.10933743e-01, -1.13100745e-01,  1.42477199e-01,\n",
       "       -4.80682179e-02, -1.21816374e-01, -1.35119036e-02, -2.06172466e-01,\n",
       "       -3.15023176e-02, -5.13692684e-02, -4.73002568e-02,  1.11297090e-02,\n",
       "        5.97353205e-02,  5.30744120e-02, -2.15583235e-01, -2.26286538e-02,\n",
       "        1.43696249e-01,  9.13152322e-02,  3.54549959e-02, -1.21163130e-01,\n",
       "       -1.49871945e-01, -6.41755462e-02, -1.34753019e-01,  6.01449125e-02,\n",
       "        5.99003509e-02, -6.84104115e-03, -2.29407936e-01, -1.32527547e-02,\n",
       "        3.95914018e-02,  6.29033074e-02, -8.11768547e-02,  3.48522551e-02,\n",
       "       -2.11816981e-01,  1.14817753e-01,  2.20393781e-02,  7.56427646e-02,\n",
       "       -8.87715593e-02,  6.65910393e-02, -1.47528678e-01,  1.08799115e-01,\n",
       "        8.27410594e-02, -2.57458780e-02,  1.43692926e-01,  9.26115513e-02,\n",
       "       -5.38434014e-02,  5.37077263e-02, -1.35275841e-01,  2.64222566e-02,\n",
       "       -8.87650400e-02, -1.07440785e-01, -7.13450834e-02,  1.70846134e-01,\n",
       "        7.43095502e-02, -3.79284401e-03,  4.02937010e-02,  1.40354514e-01,\n",
       "        1.08973466e-01,  2.68651247e-02,  1.41984463e-01,  6.71420917e-02,\n",
       "        2.14158613e-02,  5.98383173e-02,  2.11776927e-01,  1.03581071e-01,\n",
       "        7.55974650e-02, -1.86987668e-01, -4.62351745e-04,  4.41802070e-02])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_avg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# # Initialize Logistic Regression model\n",
    "# log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# # Train the model\n",
    "# log_reg.fit(X_train_avg, y_train)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred_LR = log_reg.predict(X_test_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame({\"id\": test_df[\"id\"], \"target\": y_pred_LR})\n",
    "# submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True)\n",
    "# svm.fit(X_train_avg, y_train)\n",
    "# y_pred_svm = svm.predict(X_test_avg)\n",
    "\n",
    "# submission = pd.DataFrame({\"id\": test_df[\"id\"], \"target\": y_pred_svm})\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],  # Number of boosting rounds\n",
    "#     'max_depth': [3, 5, 7],  # Lower depth prevents overfitting\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],  # Controls step size\n",
    "#     'subsample': [0.7, 0.8, 1],  # Prevents overfitting\n",
    "#     'colsample_bytree': [0.7, 0.8, 1],  # Feature selection per tree\n",
    "#     'gamma': [0, 0.1, 0.2],  # Regularization\n",
    "#     'reg_lambda': [0, 1, 10]  # L2 Regularization\n",
    "# }\n",
    "\n",
    "# xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "# random_search = RandomizedSearchCV(xgb, param_distributions=param_grid, n_iter=10, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "# random_search.fit(X_train_avg, y_train)\n",
    "\n",
    "# best_xgb = random_search.best_estimator_\n",
    "# y_pred_xgb = best_xgb.predict(X_test_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of boosting rounds\n",
    "    'max_depth': [3, 5, 7],  # Lower depth prevents overfitting\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Controls step size\n",
    "    'subsample': [0.7, 0.8, 1],  # Prevents overfitting\n",
    "    'colsample_bytree': [0.7, 0.8, 1],  # Feature selection per tree\n",
    "    'gamma': [0, 0.1, 0.2],  # Regularization\n",
    "    'reg_lambda': [0, 1, 10]  # L2 Regularization\n",
    "}\n",
    "xgb = XGBClassifier(random_state=42, eval_metric=\"logloss\")\n",
    "\n",
    "# Perform Randomized Search CV\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb, \n",
    "    param_distributions=param_grid, \n",
    "    n_iter=10, \n",
    "    cv=5, \n",
    "    scoring=\"accuracy\", \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train model\n",
    "random_search.fit(X_train_avg, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = best_xgb.predict(X_test_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"id\": test_df[\"id\"], \"target\": y_pred_xgb})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
